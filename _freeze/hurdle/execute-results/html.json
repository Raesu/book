{
  "hash": "e788ac8db82ec1abf8a837d097287dff",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hurdle Models\"\nshare:\n  permalink: \"https://book.martinez.fyi/hurdle.html\"\n  description: \"Business Data Science: Hurdle Models\"\n  linkedin: true\n  email: true\n  mastodon: true\n---\n\n\n\n\n![Hurdle Models](img/hurdle.jpg){.lightbox}\n\n## What are Hurdle Models and When are they Useful?\n\nHurdle models are a specialized statistical tool designed to handle data with a\npreponderance of zero values, which often defy the assumptions of conventional\ndistributions like the normal or Poisson. These models are particularly valuable\nwhen the data-generating process naturally consists of two distinct stages:\n\n1.  **Process 1: The Hurdle - Zero or Non-Zero?** This stage acts as the\n    gatekeeper, determining whether the underlying data-generating mechanism is\n    \"active\" or \"dormant.\" It essentially answers the question: Is the outcome\n    zero or non-zero?\n\n2.  **Process 2: Modeling the Non-Zeros.** Contingent upon the outcome of\n    Process 1, if the result is non-zero, this second stage steps in to model\n    the specific value it assumes. The choice of distribution for this modeling\n    phase hinges on the nature of the data and could encompass lognormal, gamma,\n    Poisson, or negative binomial distributions.\n\nConsider the scenario of analyzing user engagement with a new software feature.\nSome users might never activate the feature, perhaps due to lack of awareness or\nneed. Others who find it valuable might use it to varying extents. A hurdle\nmodel effectively captures both the probability of a user engaging with the\nfeature at all (Process 1 - crossing the 'hurdle'), and the extent of their\nengagement if they do (Process 2 - the usage intensity).\n\n### Mathematical Representation for a Hurdle Model with a Log Normal Component\n\nLet's delve into the mathematical underpinnings, keeping it as intuitive as possible.\n\n**Step 1: The Zero-Inflation Component**\n\n* Let $Z_i$ be a binary indicator variable for whether observation $i$ is zero.\n* $Z_i \\sim Bernoulli(\\theta_i)$ \n* where $\\theta_i = logit^{-1}(\\alpha_{zero} + \\tilde{X}_i \\beta_{zero} + \\tau_{zero} T_i)$ \n* $\\tilde{X}_i$ is the standardized design matrix (predictor variables) for observation $i$\n* $T_i$ is the treatment indicator (1 for treatment, 0 for control).\n\n* Priors:\n\n  * $\\alpha_{zero} \\sim Normal(\\mu_{\\alpha_{logit}}, \\sigma_{\\alpha_{logit}})$\n  * $\\beta_{zero} \\sim Normal(\\mu_{\\beta_{logit}}, \\sigma_{\\beta_{logit}})$\n  * $\\tau_{zero} \\sim Normal(\\mu_{\\tau_{logit}}, \\sigma_{\\tau_{logit}})$\n\n**Log-Normal Component**\n\n* Let $Y_i$ be the outcome variable.\n* If $Z_i = 0$ (i.e., the outcome is positive), then:\n\n  * $log(Y_i) \\sim Normal(\\mu_i, \\sigma_{lnorm}^2)$ \n  * where $\\mu_i = \\alpha_{lnorm} + \\tilde{X}_i \\beta_{lnorm} + \\tau_{lnorm} T_i$\n\n* Priors:\n\n  * $\\alpha_{lnorm} \\sim Normal(\\mu_{log(y)}, 1)$\n  * $\\beta_{lnorm} \\sim Normal(0, 0.5)$\n  * $\\tau_{lnorm} \\sim Normal(\\mu_{\\tau}, \\sigma_{\\tau})$ \n  * $\\sigma_{lnorm} \\sim Normal(0, 0.5)$ \n\n**Combined Model**\n\n* The overall likelihood for observation $i$ is:\n\n* $P(Y_i = 0) = \\theta_i$\n* $P(Y_i > 0) = (1 - \\theta_i) \\times \\frac{1}{Y_i \\sigma_{lnorm} \\sqrt{2\\pi}} exp \\left( -\\frac{(log(Y_i) - \\mu_i)^2}{2 \\sigma_{lnorm}^2} \\right)$\n\n\n## Simulating Data for a Hurdle Model\n\nLet's bring these concepts to life with a practical example. Imagine you're part\nof an online video content company aiming to assess the impact of a novel\nmarketing strategy on video watch time. You notice that certain videos garner\nsubstantial watch time, while others remain unwatched. To rigorously test this\nnew strategy, you randomly assign videos to either a treatment or control group.\nHere's how we might simulate such data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nset.seed(123)\nn <- 3000\n\n# Simulate covariates (unchanged)\nfake_data <- data.frame(\n  genre = sample(c(\"Comedy\", \"Education\", \"Music\"), n, replace = TRUE),\n  length = stats::rnorm(n, mean = 10, sd = 3),\n  popular_channel = stats::rbinom(n, 1, 0.2)\n)\n\n# Treatment indicator (unchanged)\nfake_data$treatment <- stats::rbinom(n, 1, 0.5)\n\n# Model parameters (coefficients) - unchanged\nbeta_zero <- c(0.5, -0.2, 1)\nbeta_mean <- c(2, 0.1, 0.5)\n\n# Modified treatment effect for zero probability\n# We want P(zero | treated) = P(zero | control) - 0.05\n# Assuming P(zero | control) = 0.3 \np_zero_control <- 0.3\np_zero_treated <- p_zero_control - 0.05\ntreatment_effect_zero_prob <- qlogis(p_zero_treated) - qlogis(p_zero_control)\n\n# Treatment effect for watch time \ntreatment_effect_watch_time <- 2\n\n# Linear predictors (with modified treatment effect)\nzero_prob_logit <- beta_zero[1] +\n                   ifelse(fake_data$genre == \"Education\", beta_zero[2], 0) +\n                   beta_zero[3] * fake_data$popular_channel +\n                   treatment_effect_zero_prob * fake_data$treatment\n\nlog_normal_mean <- beta_mean[1] +\n                   beta_mean[2] * fake_data$length +\n                   beta_mean[3] * fake_data$popular_channel +\n                   treatment_effect_watch_time * fake_data$treatment\n\n# Generate potential outcomes\nfake_data <- within(fake_data, {\n    zero_prob_control <- stats::plogis(zero_prob_logit - treatment_effect_zero_prob * treatment)\n    zero_prob_treated <- stats::plogis(zero_prob_logit)\n    watch_time_control <- ifelse(stats::rbinom(n, 1, 1 - zero_prob_control) == 1,\n                                 stats::rlnorm(n, log_normal_mean - treatment_effect_watch_time * treatment, 0.5),\n                                 0)\n    watch_time_treated <- ifelse(stats::rbinom(n, 1, 1 - zero_prob_treated) == 1,\n                                 stats::rlnorm(n, log_normal_mean, 0.5),\n                                 0)\n    # Calculate treatment effects\n    tau_watch_time <- watch_time_treated - watch_time_control\n    tau_zero_prob <- zero_prob_treated - zero_prob_control\n    # Observed outcome based on treatment assignment\n    zero_prob <- ifelse(treatment == 1, zero_prob_treated, zero_prob_control)\n    watch_time <- ifelse(treatment == 1, watch_time_treated, watch_time_control)\n}) |>\n  dplyr::mutate(treatment = as.logical(treatment))\n\n\n\ndplyr::glimpse(fake_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,000\nColumns: 12\n$ genre              <chr> \"Music\", \"Music\", \"Music\", \"Education\", \"Music\", \"E…\n$ length             <dbl> 6.708240, 16.357660, 9.374124, 8.238192, 8.547379, …\n$ popular_channel    <int> 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, …\n$ treatment          <lgl> TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE…\n$ watch_time         <dbl> 100.22589, 73.82856, 244.60962, 0.00000, 37.70174, …\n$ zero_prob          <dbl> 0.5618529, 0.6224593, 0.7770722, 0.5121690, 0.81757…\n$ tau_zero_prob      <dbl> -0.06060638, 0.00000000, -0.04050223, -0.06227353, …\n$ tau_watch_time     <dbl> 100.2258876, -73.8285590, 244.6096222, 0.0000000, 1…\n$ watch_time_treated <dbl> 100.225888, 0.000000, 244.609622, 0.000000, 39.4416…\n$ watch_time_control <dbl> 0.00000, 73.82856, 0.00000, 0.00000, 37.70174, 0.00…\n$ zero_prob_treated  <dbl> 0.5618529, 0.6224593, 0.7770722, 0.5121690, 0.81757…\n$ zero_prob_control  <dbl> 0.6224593, 0.6224593, 0.8175745, 0.5744425, 0.81757…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(fake_data, aes(x = watch_time)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribution of Watch Time\", x = \"Watch Time\", y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](hurdle_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\nIn this simulated data, the average treatment effect leads to an increase in\nwatch time of approximately 30 hours.\nAdditionally, the probability of having zero hours of watch time decreases by\n-3 percentage points.\n\n## Pitfalls of Naive OLS Regression\n\nSince treatment assignment is random in our simulation, it might be\ntempting to use a simple linear regression:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(data = fake_data, \n   watch_time ~ genre + popular_channel + length + treatment) |> \n  broom::tidy(conf.int = TRUE)\n\nlm1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  term            estimate std.error statistic   p.value conf.low conf.high\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)       -19.8      5.64     -3.51  4.49e-  4   -30.9      -8.75\n2 genreEducation      4.27     3.50      1.22  2.23e-  1    -2.59     11.1 \n3 genreMusic         -1.42     3.44     -0.411 6.81e-  1    -8.17      5.34\n4 popular_channel   -10.0      3.48     -2.88  4.06e-  3   -16.8      -3.19\n5 length              3.01     0.482     6.26  4.54e- 10     2.07      3.96\n6 treatmentTRUE      63.3      2.83     22.4   1.14e-102    57.8      68.9 \n```\n\n\n:::\n:::\n\n\n\n\nHowever, this approach overestimates the true treatment effect. The\npoint estimate and confidence intervals are significantly higher than\nthe actual impact.\n\nAnother common approach is to log-transform the outcome variable and\nthen apply OLS:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run the OLS regression with log(watch_time + 1) as the dependent variable\nlm2 <- lm(data = fake_data, log(watch_time + 1) ~ genre +\n            popular_channel + length + treatment) |> \n  broom::tidy(conf.int = TRUE)\n\nlm2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  term            estimate std.error statistic  p.value  conf.low conf.high\n  <chr>              <dbl>     <dbl>     <dbl>    <dbl>     <dbl>     <dbl>\n1 (Intercept)       0.975     0.147      6.61  4.40e-11  0.686       1.26  \n2 genreEducation    0.164     0.0915     1.79  7.28e- 2 -0.0152      0.344 \n3 genreMusic        0.0373    0.0900     0.415 6.79e- 1 -0.139       0.214 \n4 popular_channel  -0.777     0.0911    -8.54  2.17e-17 -0.956      -0.599 \n5 length            0.0240    0.0126     1.91  5.65e- 2 -0.000670    0.0487\n6 treatmentTRUE     0.923     0.0740    12.5   6.80e-35  0.778       1.07  \n```\n\n\n:::\n\n```{.r .cell-code}\nmean_watch_time_control <- mean(fake_data$watch_time[fake_data$treatment == FALSE]) \n\npoint_estimate <- mean_watch_time_control*(1+lm2$estimate[6])\nlb <- mean_watch_time_control*(1+lm2$conf.low[6])\nub <- mean_watch_time_control*(1+lm2$conf.high[6])\n```\n:::\n\n\n\n\nIn this case, the point estimate (18) and the\nconfidence interval ([16, 19]) underestimate the\ntrue effect.\n\n## Bayesian Hurdle Model Using {imt}\n\n<img src=\"https://raw.githubusercontent.com/google/imt/refs/heads/main/man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"logo of the imt package\" />\n\nLet's use the [{imt}](https://github.com/google/imt) package to fit a Bayesian\nhurdle model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(imt)\n\n# Create the hurdleLogNormal object\nmodel <- hurdleLogNormal$new(\n  data = fake_data,\n  y = \"watch_time\",\n  x = c(\"length\", \"popular_channel\", \"genre\"),\n  treatment = \"treatment\",\n  tau_mean_logit = 0,\n  tau_sd_logit = 0.5,\n  mean_tau = 0,\n  sigma_tau = 0.035\n)\n```\n:::\n\n\n\n\n### Plot Priors\n\nBefore diving into the posterior analysis, let's visualize the priors we've set\nfor our model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_plots <- model$plotPrior(bins = 1000,\n                               xlim_ate = c(-500, 500),\n                               xlim_tau = c(-10, 10))\n\n# To display the plots:\nprior_plots$ate_prior\n```\n\n::: {.cell-output-display}\n![](hurdle_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nprior_plots$tau_prior\n```\n\n::: {.cell-output-display}\n![](hurdle_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n\n\nThese plots provide a visual representation of our prior beliefs about the\ntreatment effects before observing the data.\n\n### Posterior Analysis\n\nNow, let's examine the posterior distribution and assess the model's fit:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppc_plot <- model$posteriorPredictiveCheck(n = 50, xlim = c(0, 500))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n```\n\n\n:::\n\n```{.r .cell-code}\nppc_plot  # Display the plot\n```\n\n::: {.cell-output-display}\n![](hurdle_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nThe posterior predictive check helps us gauge whether the model adequately\ncaptures the characteristics of the observed data.\n\nFinally, let's extract the key estimates:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get ATE point estimate and credible interval\nate <- model$pointEstimate(\"ATE\")\nci_statement <- model$credibleInterval(\"ATE\")\n\n# Print results\ncat(\"The mean of the posterior distribution of the average treatment effect is\", \n    round(ate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe mean of the posterior distribution of the average treatment effect is 32\n```\n\n\n:::\n\n```{.r .cell-code}\nci_statement\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGiven the data, we estimate that there is a 95% probability that the ATE is between 26.52 and 37.9.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get ATE point estimate and credible interval\ntau_prob_zero <- model$pointEstimate(\"tau_prob_zero\") \nci_statement <- model$credibleInterval(\"tau_prob_zero\")\n\n# Print results\ncat(\"The mean of the posterior distribution of the effect on the probability of a zero is\", \n    round(tau_prob_zero,4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe mean of the posterior distribution of the effect on the probability of a zero is -0.0457\n```\n\n\n:::\n\n```{.r .cell-code}\nci_statement\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGiven the data, we estimate that there is a 95% probability that the tau_prob_zero is between -0.09 and 0.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel$calcProb(effect_type = \"ATE\", a = 29)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGiven the data, we estimate  that the probability that the ATE is more than 29 is 86%.\n```\n\n\n:::\n:::\n\n\n\n\n\nThe Bayesian hurdle model, as implemented with {imt}, provides a more nuanced\nand accurate assessment of the treatment effect in the presence of excessive\nzeros, outperforming naive OLS approaches.\n\n## Hurdle vs. Zero-Inflated Models: Choosing the Right Tool for the Job\n\nWhile hurdle models excel at handling data with excess zeros, it's crucial to\ndistinguish them from another class of models designed for similar scenarios:\nzero-inflated models. Both tackle the challenge of zero inflation, but they do\nso with subtle yet important differences.\n\n### Conceptual Differences\n\n  - **Hurdle Models:** Assume a single process generates both zeros and\n    non-zeros. The \"hurdle\" represents a threshold that must be crossed before\n    any non-zero outcome can occur. Think of it as a binary decision: either the\n    outcome is zero, or it's something positive that we then model with a\n    suitable distribution.\n  \n  - **Zero-Inflated Models:** Assume two distinct processes are at play. One\n    process generates only zeros (the \"structural zeros\"), while another process\n    generates both zeros and non-zeros (the \"count process\"). This allows for\n    the possibility of \"excess zeros\" beyond what would be expected from the\n    count process alone.\n    \n### When to Use Each\n\n  - **Hurdle Models:** Ideal when there's a clear conceptual hurdle or threshold\n    that needs to be overcome before a non-zero outcome can happen. For\n    instance, in our video watch time example, users need to decide to watch a\n    video at all before any watch time can be recorded.\n\n  - **Zero-Inflated Models:** More suitable when you suspect there are two\n    fundamentally different types of zeros in your data. For example, in a\n    survey about alcohol consumption, some respondents might be teetotalers\n    (structural zeros), while others might simply not have consumed alcohol\n    during the survey period (zeros from the count process).\n    \nThe choice between a hurdle model and a zero-inflated model hinges on your\nunderstanding of the data-generating process and the research question at hand.\nIf you believe there's a single process with a clear hurdle, a hurdle model is\nthe way to go. If you suspect multiple processes leading to zeros, a\nzero-inflated model might be more appropriate.\n\nIn our video watch time example, we opted for a hurdle model because the\ndecision to watch a video (or not) seemed like a natural hurdle. However, if we\nhad reason to believe that some videos were inherently unappealing and would\nnever be watched by anyone (structural zeros), a zero-inflated model might have\nbeen worth considering.\n\nThe key takeaway is that both hurdle and zero-inflated models offer powerful\nways to handle excess zeros, but their underlying assumptions and\ninterpretations differ.\n\nBy carefully considering the nature of your data and your research goals, you\ncan choose the model that best suits your needs and unlocks valuable insights\nhidden within the zeros.  \n\n::: {.callout-tip}\n## Learn more\n  - @mc-stan2024finite Stan User's Guide: Finite Mixtures and Zero-inflated Models.\n  - @heiss2022hurdle: A guide to modeling outcomes that have lots of zeros with Bayesian hurdle lognormal and hurdle Gaussian regression models.\n::: ",
    "supporting": [
      "hurdle_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}