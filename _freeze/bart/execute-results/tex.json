{
  "hash": "deea87f6b6704671e212d414da7b54ab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Additive Regression Trees (BART)\"\n---\n\n\n\n## BART: Bayesian Additive Regression Trees\n\nBART is a Bayesian nonparametric, machine learning, ensemble predictive modeling\nmethod introduced by @chipman2010bart. It can be expressed as:\n\n$$\nY = \\sum_{j=1}^m g(X; T_j, M_j) + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2)\n$$\n\nwhere $g(X; T_j, M_j)$ represents the $j$-th regression tree with structure\n$T_j$ and leaf node parameters $M_j$. The model uses $m$ trees, typically set to\na large number (e.g., 200), with each tree acting as a weak learner. BART\nemploys a carefully designed prior that encourages each tree to play a small\nrole in the overall fit, resulting in a flexible yet robust model.\n\n@hill2011bayesian proposed using BART for causal inference, recognizing that its\nflexibility in modeling complex response surfaces made it well-suited for\nestimating causal effects, particularly in observational studies with many\ncovariates. The key idea was to use BART to model the response surface:\n\n$$\nE[Y | X, Z] = f(X, Z)\n$$\n\nwhere $Y$ is the outcome, $X$ are the covariates, and $Z$ is the treatment\nindicator. The causal effect can then be estimated as:\n\n$$\n\\begin{aligned}\n\\tau(x) & = E[Y | X=x, Z=1] - E[Y | X=x, Z=0] \\\\\n & = f(x, 1) - f(x, 0)\n\\end{aligned}\n$$\n\nThis formulation leverages BART's inherent ability to automatically capture\nintricate interactions and non-linear relationships, making it a potent tool for\ncausal inference, especially in high-dimensional scenarios.\n\nThe effectiveness of BART in causal inference has been further validated in\nrecent competitions. @thal2023causal report on the 2022 American Causal\nInference Conference (ACIC) data challenge, where BART-based methods were among\nthe top performers, particularly for estimating heterogeneous treatment effects.\nThey found that BART's regularizing priors were especially effective in\ncontrolling error for subgroup estimates, even in small subgroups, and its\nflexibility in modeling confounding relationships was crucial for improved\ncausal inference in complex scenarios.\n\n## Example with a Single Covariate\n\nTo illustrate how BART can be used for estimating the impact of an intervention,\n@hill2011bayesian presents a simple example:\n\n\n$$\n\\begin{aligned}\nZ &\\sim \\mbox{Bernoulli}(0.5) \\\\\nX | Z = 1 &\\sim N(40,10^2) \\\\\nX | Z = 0 &\\sim N(20,10^2) \\\\\nY(0) | X &\\sim N(72 + 3\\sqrt{X},1) \\\\\nY(1) | X &\\sim N(90 + exp(0.06X),1) \n\\end{aligned}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom) \n\n# 1. Define True Outcome Functions\nf_treated <- function(x) 90 + exp(0.06 * x)\nf_control <- function(x) 72 + 3 * sqrt(x)\n\n# 2. Visualize True Outcome Functions\nggplot(data.frame(x = 6:62), aes(x = x)) +  # Expanded x range for clarity\n  stat_function(fun = f_control, aes(color = \"Truth - Control\"), linewidth = 1) +  \n  stat_function(fun = f_treated, aes(color = \"Truth - Treatment\"), linewidth = 1) +\n  scale_color_manual(values = c(\"red\", \"blue\")) +\n  labs(title = \"True Outcome Functions\", x = \"X\", y = \"Y\", color = \"\") +\n  theme_bw() +   \n  theme(legend.position = \"bottom\")  \n```\n\n::: {.cell-output-display}\n![](bart_files/figure-pdf/truth-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nWe can generate a sample from that data generating process as follows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn_samples <- 120\n\nsimulated_data <- tibble(\n  treatment_group = sample(c(\"Treatment\", \"Control\"), size = n_samples, replace = TRUE),\n  is_treated = treatment_group == \"Treatment\",\n  X = if_else(is_treated, rnorm(n_samples, 40, 10), rnorm(n_samples, 20, 10)),\n  Y1 = rnorm(n_samples, mean = f_treated(X), sd = 1),  \n  Y0 = rnorm(n_samples, mean = f_control(X), sd = 1),  \n  Y = if_else(is_treated, Y1, Y0),\n  true_effect = Y1 - Y0\n)\n\n\n# 4. Visualize Simulated Data with True Functions\nggplot(simulated_data, aes(x = X, y = Y, color = treatment_group)) +\n  geom_point(size = 2) + \n  stat_function(fun = f_control, aes(color = \"Truth - Control\")) +\n  stat_function(fun = f_treated, aes(color = \"Truth - Treatment\")) +\n  scale_color_manual(values = c(\"Truth - Control\" = \"red\", \"Truth - Treatment\" = \"blue\")) +  # Mapping colors correctly\n  labs(title = \"Simulated Data with True Outcome Functions\", \n       x = \"X\", y = \"Y\", color = \"\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\") \n```\n\n::: {.cell-output-display}\n![](bart_files/figure-pdf/sample-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ncat(glue::glue(\"The true Sample Average Treatment Effect is {round(mean(simulated_data$true_effect),2)}\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe true Sample Average Treatment Effect is 10.84\n```\n\n\n:::\n:::\n\n\n\nNotice that in our sample, there is not very good overlap for low and high\nvalues of X. This means that we will have to do a lot of extrapolation when\ndoing inference for those cases, which is a common challenge in causal\ninference. Now, suppose we just fit OLS to the model to try to estimate the\naverage treatment effect:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_model <- lm(Y ~ X + is_treated, data = simulated_data)\nlm_fit <- broom::tidy(linear_model)\nlm_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      70.1      1.29       54.6  4.71e-85\n2 X                 0.715    0.0486     14.7  2.24e-28\n3 is_treatedTRUE    4.74     1.30        3.64 4.14e- 4\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(glue::glue(\"A linear model finds an Average Treatment Effect equal to {round(lm_fit$estimate[lm_fit$term=='is_treatedTRUE'],2)}\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA linear model finds an Average Treatment Effect equal to 4.74\n```\n\n\n:::\n:::\n\n\n\nIt's important to note that the linear model is misspecified given the true\nnonlinear relationships, which contributes to its poor performance. Let's add\nthe findings from OLS to our plot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_data <- expand.grid(\n  X = seq(min(simulated_data$X), max(simulated_data$X), length.out = 1000),\n  is_treated = c(TRUE, FALSE)\n) %>%\n  mutate(\n    treatment_group = if_else(is_treated, \"Treatment\", \"Control\"),\n    linear_prediction = predict(linear_model, newdata = .)\n  )\n\n# 6. Visualize Simulated Data, True Functions, and Linear Predictions\nggplot() +\n  geom_point(data = simulated_data, aes(x = X, y = Y, color = treatment_group), size = 2) +\n  stat_function(fun = f_control, aes(color = \"Truth - Control\")) +\n  stat_function(fun = f_treated, aes(color = \"Truth - Treatment\")) +\n  geom_line(data = prediction_data, aes(x = X, y = linear_prediction, \n                                        color = treatment_group), linetype = \"dashed\") +\n  scale_color_manual(values = c(\"Truth - Control\" = \"red\",  \n                                \"Truth - Treatment\" = \"blue\",\n                                \"Control\" = \"red\",           \n                                \"Treatment\" = \"blue\")) +    \n  labs(title = \"Simulated Data, True Functions, and Linear Model Predictions\",\n       x = \"X\", y = \"Y\", color = \"\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\") \n```\n\n::: {.cell-output-display}\n![](bart_files/figure-pdf/ols_plot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nTo fit BART we can use the [{stochtree}](https://stochastictree.github.io/stochtree-r/) package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxstart <- 20-15\nlength <- 4\ntext_left <- 26-15\nyVals <- seq(110,130,by=4)\n\nX_train <- simulated_data %>% \n                    select(X, is_treated) %>% \n                    as.matrix()\n\nX_test <- prediction_data %>% \n                    select(X, is_treated) %>% \n                    as.matrix()\n\nbart_model <-\n  stochtree::bart(X_train = X_train,\n                  X_test = X_test,\n                  y_train = simulated_data$Y,\n                  num_burnin = 1000,\n                  num_mcmc = 2000)\n```\n:::\n\n\n\nAfter fitting, it is important to examine the traceplot of $\\sigma^2$ to assess\nif the model has converged. We can do this by running the following code:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrace_plot_data <-\n  tibble(\n    iteration = 1:length(bart_model$sigma2_samples),\n    sigma2_samples = bart_model$sigma2_samples\n  )\nggplot(aes(x = iteration, y = sigma2_samples), data = trace_plot_data) +\n  geom_line(color = \"blue\", alpha = 0.5) +\n  labs(title = \"Trace Plot for sigma^2\",\n       x = \"Iteration\",\n       y = \"sigma^2\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](bart_files/figure-pdf/traceplot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nNow we can plot the predictions from BART and compare them to the truth with the\nfollowing code:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_data <- prediction_data %>%\n  mutate(bart_pred = rowMeans(bart_model$y_hat_test)) \n\n\nggplot() +\n  geom_point(data = simulated_data,\n             aes(x = X, y = Y, color = treatment_group),\n             size = 2) +\n  stat_function(fun = f_control, aes(color = \"Truth - Control\")) +\n  stat_function(fun = f_treated, aes(color = \"Truth - Treatment\")) +\n  scale_color_manual(\n    values = c(\n      \"Truth - Control\" = \"red\",\n      \"Truth - Treatment\" = \"blue\",\n      \"Control\" = \"red\",\n      \"Treatment\" = \"blue\"\n    )\n  ) +\n  labs(\n    title = \"Simulated Data, True Functions, and BART Predictions\",\n    x = \"X\",\n    y = \"Y\",\n    color = \"\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  geom_line(data = prediction_data,\n            aes(x = X, y = bart_pred, color = treatment_group),\n            linetype = \"dashed\") +\n   scale_color_manual(\"\", values = c(\"red\", \"blue\",\"red\", \"blue\", \"red\", \"blue\", \"red\", \"blue\")) +\n   annotate(geom = \"segment\", x = xstart, y = yVals[1], xend = xstart+length, yend = yVals[1], color = \"red\") +\n   annotate(geom = \"text\", x = text_left, y = yVals[1], label = c(\"truth - control\"), hjust = 0) +\n   annotate(geom = \"segment\", x = xstart, y = yVals[2], xend = xstart+length, yend = yVals[2], color = \"blue\") +\n   annotate(geom = \"text\", x = text_left, y = yVals[2], label = c(\"truth - treatment\"), hjust = 0) +\n   geom_point(aes(x=xstart+length/2, y=yVals[3]), color = c(\"red\")) +\n   annotate(geom = \"text\", x = text_left, y = yVals[3], label = c(\"simulated data - control\"), hjust = 0) +\n   geom_point(aes(x=xstart+length/2, y=yVals[4]), color = c(\"blue\")) +\n   annotate(geom = \"text\", x = text_left, y = yVals[4], label = c(\"simulated data - treatment\"), hjust = 0) +\n   annotate(geom = \"segment\", x = xstart, y = yVals[5], xend = xstart+length, yend = yVals[5], color = \"red\", linetype = \"dashed\") +\n   annotate(geom = \"text\", x = text_left, y = yVals[5], label = c(\"BART - control\"), hjust = 0) +\n   annotate(geom = \"segment\", x = xstart, y = yVals[6], xend = xstart+length, yend = yVals[6], color = \"blue\", linetype = \"dashed\") +\n   annotate(geom = \"text\", x = text_left, y = yVals[6], label = c(\"BART - treatment\"), hjust = 0) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](bart_files/figure-pdf/bart_plot-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nNotice that BART does a very good job when we have overlap between the treatment\nand control groups, but when extrapolating for high values of X, BART cannot get\nthe true control curve right because it has no data in that region. This\nhighlights the importance of understanding how any method works.\n\n\nOnce we have fitted the BART model, we can calculate the sample average\ntreatment effect by predicting the outcome for every individual in our sample\nunder both treatment and control conditions. The difference between these\npredictions gives us the posterior distribution of the treatment effect for each\nindividual. The sample average treatment effect is then the mean of this\nposterior distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx0 <- simulated_data %>% mutate(is_treated=FALSE) %>% select(X,is_treated)\nx1 <- simulated_data %>% mutate(is_treated=TRUE) %>% select(X,is_treated)\n\npred0 <- predict(bart_model, as.matrix(x0))\n\npred1 <- predict(bart_model, as.matrix(x1))\n\ntau_draws <- pred1$y_hat - pred0$y_hat  \nsate_draws <- colMeans(tau_draws)\ncat(glue::glue(\"BART finds an Average Treatment Effect equal to {round(mean(sate_draws),2)}\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBART finds an Average Treatment Effect equal to 9.74\n```\n\n\n:::\n:::\n\n\n\nHowever, as we discussed before, point estimates are often not very useful for\ndecision-making. For instance, we might make different decisions if the impact\nof the intervention is more than 9, between 0 and 9, or less than 0. Calculating\nprobabilities for different effect sizes is more useful for decision-making than\npoint estimates alone because it provides a more nuanced understanding of the\npotential outcomes and the uncertainty associated with our estimates.\n::: {.content-visible when-format=\"pdf\"}\nWe can easily calculate these probabilities using the draws from the posterior\nprobability that we just calculated.\n::: \n::: {.content-visible when-format=\"html\"}\nWe can easily calculate these probabilities using the posterior draws and visualize\nthem:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvizdraws::vizdraws(\n  posterior = sate_draws,\n  breaks = c(0, 9),\n  break_names = c(\"Discontinue\", \"Continue\", \" Expand\")\n)\n```\n:::\n\n\n:::\n\n## Accelerated BART (XBART)\n\nTODO",
    "supporting": [
      "bart_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}